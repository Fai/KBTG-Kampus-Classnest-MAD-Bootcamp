{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fai/KBTG-Kampus-Classnest-MAD-Bootcamp/blob/main/MAD_Post_Labs_(LLM_Module).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# M.A.D Post Labs (LLM Module)\n",
        "\n",
        "In this lab, you will implement a basic LLM-powered application. There are **three parts** that you need to complete:\n",
        "<br>\n",
        "* OpenAI's API and ReAct Agent\n",
        "* LLM Applications\n",
        "* Sentiment Analysis\n",
        "</br>\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "* Completing all tasks will earn you **100 points.**\n",
        "* You can navigate through your tasks by looking for the **TODO, TO DO, fill in the blank, _** text in this lab.\n",
        "* Please **keep the \\<TODO_OUTPUT_BEGIN\\> tag** for grading purposes.\n",
        "* Any case of plagiarism will result in a **zero score for all plagiarized submissions**."
      ],
      "metadata": {
        "id": "jCzd0DIpEEYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites\n",
        "\n",
        "Before we start, please fill in your information. This information will be used in the grading system."
      ],
      "metadata": {
        "id": "5pyHUvx5EH4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ***** RUN THIS CELL *****\n",
        "\n",
        "AUTHOR_NAME = \"YOUR_NAME_IN_ENGLISH\"\n",
        "AUTHOR_SURNAME = \"YOUR_SURNAME_IN_ENGLISH\"\n",
        "AUTHOR_NICKNAME = \"YOUR_NICKNAME_IN_ENGLISH\"\n",
        "\n",
        "### ***** RUN THIS CELL *****"
      ],
      "metadata": {
        "id": "2ZLTiUOuEM8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to install the following libraries to assist in completing the labs."
      ],
      "metadata": {
        "id": "HPO1kNHTEO2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q requests==2.32.3\n",
        "!pip install -q openai==1.41.1\n",
        "!pip install -q langchain==0.2.2\n",
        "!pip install -q langchain_community==0.2.3\n",
        "!pip install -q langchain-openai==0.1.8\n",
        "!pip install -q langgraph==0.0.64"
      ],
      "metadata": {
        "id": "O6gp_oy1EOKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You also need an OpenAI account with **valid API keys**.\n",
        "\n",
        "1) If you have not registered before, you can do so at https://platform.openai.com/login?launch\n",
        "\n",
        "2) Then, the API key can be generated from https://platform.openai.com/api-keys\n",
        "\n",
        "Note: For first-time use, there will be a $5 free credit from OpenAI (valid for 30 days)."
      ],
      "metadata": {
        "id": "s_Nxdf4RENwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: OpenAI's API and ReAct Agent [35 Points]"
      ],
      "metadata": {
        "id": "KV2r5OI9_mfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Calling OpenAI APIs [20 Points]\n",
        "\n",
        "In this tasks, you are to implement a code which call OpenAI APIs.\n",
        "\n",
        "**Before we begin, ensure the ‘OPENAI_API_KEY’ is added in the Secrets tab (key icon on the left).**\n",
        "\n",
        "<img src =\"https://raw.githubusercontent.com/jrkns/cloud_imgs/main/210824_colab_secret.png\" width=\"500\" height=\"300\">"
      ],
      "metadata": {
        "id": "4syIOGBr_RzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-1: Sent first OpenAI API request. [2.5 Points]\n",
        "\n",
        "Ensure that you correctly generate and configure the OpenAI API key by running the code below. The output **should display your first and last name** for grading purposes. If it doesn't, **please set the variables and rerun the cell in the prerequisite section above**."
      ],
      "metadata": {
        "id": "wWyykKKcxjyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Make sure OPENAI_API_KEY is added in the Secrets tab\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "#\n",
        "### TODO-1: Sent first OpenAI API request. [2.5 Points]\n",
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"My name is \\\"{AUTHOR_NAME} {AUTHOR_SURNAME}\\\", What is my name?\"}\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "#\n",
        "print(\"<TODO_1_OUTPUT_BEGIN>\")\n",
        "print(completion)\n",
        "print(completion.choices[0].message)\n",
        "print(\"<TODO_1_OUTPUT_END>\")\n",
        "#\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "PjVS4bs8_ScG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-2: Look at the EXPECTED-OUTPUT and try to guess the prompts. [5 Points]\n",
        "\n",
        "Your task is to guess the original prompt that generated the contents below. The **output may differ** from the expected output in details (e.g., location names), but the **schema of the output should match**.\n",
        "\n",
        "**Hint:** Consider passing additional parameters to OpenAI to ensure the JSON output is valid. https://platform.openai.com/docs/guides/structured-outputs/json-mode"
      ],
      "metadata": {
        "id": "pzwe3U6zxq9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-2: Look at the EXPECTED-OUTPUT and try to guess the prompts. [5 Points]\n",
        "###         The output may vary in details, but the main components should match.\n",
        "TODO_2_PROMPTS = \"\"\"\n",
        "    <Fill in your prompt here>\n",
        "\"\"\"\n",
        "\n",
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": TODO_2_PROMPTS}\n",
        "    ],\n",
        "    # temperature=?,\n",
        "    # ???=?\n",
        ")\n",
        "\n",
        "### EXPECTED-OUTPUT (may vary):\n",
        "# <TODO_2_OUTPUT_BEGIN>\n",
        "# {'trip': [{'name': 'Chatuchak Weekend Market',\n",
        "#    'station': 'Mo Chit',\n",
        "#    'time': 'morning'},\n",
        "#   {'name': 'Jim Thompson House',\n",
        "#    'station': 'National Stadium',\n",
        "#    'time': 'afternoon'},\n",
        "#   {'name': 'Wat Arun (Temple of Dawn)',\n",
        "#    'station': 'Sathorn (Taksin) - then take a ferry',\n",
        "#    'time': 'morning'},\n",
        "#   {'name': 'Asiatique The Riverfront',\n",
        "#    'station': 'Sathorn (Taksin) - then take a ferry',\n",
        "#    'time': 'afternoon'}]}\n",
        "# <TODO_2_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "print(\"<TODO_2_OUTPUT_BEGIN>\")\n",
        "print(json.loads(completion.choices[0].message.content))\n",
        "print(\"<TODO_2_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "WN_KsB8xEgNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-3: Look at the EXPECTED-OUTPUT and try to guess the prompts. [5 Points]\n",
        "\n",
        "Your task is to guess the original prompt that generated the contents below. The **output may differ** from the expected output in details (e.g., location names), but the **schema of the output should match**.\n",
        "\n",
        "**Hint:** Consider passing additional parameters to OpenAI to ensure the JSON output is valid. https://platform.openai.com/docs/guides/structured-outputs/json-mode"
      ],
      "metadata": {
        "id": "b9t3OFnGHbaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-3: Look at the EXPECTED-OUTPUT and try to guess the prompts. [5 Points]\n",
        "###         The output may vary in details, but the main components should match.\n",
        "TODO_3_PROMPTS = \"\"\"\n",
        "    <Fill in your prompt here>\n",
        "\"\"\"\n",
        "\n",
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def secret_logic(input_string):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": TODO_3_PROMPTS},\n",
        "            {\"role\": \"user\", \"content\": f\"text: {input_string}\\noutput:\"}\n",
        "        ],\n",
        "        # temperature=?,\n",
        "        # ???=?\n",
        "    )\n",
        "    return json.loads(completion.choices[0].message.content)\n",
        "\n",
        "### EXPECTED-OUTPUT:\n",
        "# <TODO_3_OUTPUT_BEGIN>\n",
        "# INPUT: Hi, I’m Bob. Your credit card is amazing.\n",
        "# OUTPUT: {'name': 'Bob', 'sentiment': 'positive', 'products': ['credit_card']}\n",
        "# INPUT: Your debit card was not working, so I couldn’t use it at the airport yesterday :(\n",
        "# OUTPUT: {'name': 'unknown', 'sentiment': 'negative', 'products': ['debit_card']}\n",
        "# INPUT: Last week, my wife Alice lost her wallet, and both her debit and credit cards are gone. Your customer service responded quickly to freeze those cards. Thank you again.\n",
        "# OUTPUT: {'name': 'Alice', 'sentiment': 'positive', 'products': ['debit_card', 'credit_card']}\n",
        "# <TODO_3_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "inpts = [\n",
        "    \"Hi, I’m Bob. Your credit card is amazing.\",\n",
        "    \"Your debit card was not working, so I couldn’t use it at the airport yesterday :(\",\n",
        "    \"Last week, my wife Alice lost her wallet, and both her debit and credit cards are gone. Your customer service responded quickly to freeze those cards. Thank you again.\"\n",
        "]\n",
        "#\n",
        "print(\"<TODO_3_OUTPUT_BEGIN>\")\n",
        "for inpt in inpts:\n",
        "    print(\"INPUT:\", inpt)\n",
        "    print(\"OUTPUT:\", secret_logic(inpt))\n",
        "print(\"<TODO_3_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "o7g3Tvj7EgC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-4: Look at the EXPECTED-OUTPUT and try to guess the prompts. [5 Points]\n",
        "\n",
        "Your task is to guess the original prompt that generated the contents below. **The output should match perfectly.**"
      ],
      "metadata": {
        "id": "lXi38SoxHfad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-4: Look at the EXPECTED-OUTPUT and try to guess the prompts. [5 Points]\n",
        "###         The output may vary in details, but the main components should match.\n",
        "TODO_4_PROMPTS = \"\"\"\n",
        "    <Fill in your prompt here>\n",
        "\"\"\"\n",
        "\n",
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Write a Christmas tree using the * symbol. Only respond with the tree.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"```\\n      *      \\n     ***     \\n    *****    \\n   *******   \\n  *********  \\n *********** \\n*************\\n      |      \\n```\"},\n",
        "        {\"role\": \"user\", \"content\": TODO_4_PROMPTS},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "### BEFORE-OUTPUT:\n",
        "# ```\n",
        "#       *\n",
        "#      ***\n",
        "#     *****\n",
        "#    *******\n",
        "#   *********\n",
        "#  ***********\n",
        "# *************\n",
        "#       |\n",
        "# ```\n",
        "\n",
        "### EXPECTED-OUTPUT:\n",
        "# <TODO_4_OUTPUT_BEGIN>\n",
        "# ```\n",
        "#       $\n",
        "#      $$$\n",
        "#     $$$$$\n",
        "#    $$$$$$$\n",
        "#       |\n",
        "# ```\n",
        "# <TODO_4_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "print(\"<TODO_4_OUTPUT_BEGIN>\")\n",
        "print(completion.choices[0].message.content)\n",
        "print(\"<TODO_4_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "QmphZfy7Ef7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-5: Write a code that includes prompts and Vision API calls. [2.5 Points]\n",
        "\n",
        "\n",
        "**Working with images**\n",
        "\n",
        "In this task, you will implement code to use the OpenAI Vision API to identify **legs present in the following image.** **The output may vary.**\n",
        "\n",
        "Image: https://takabb.com/public/images/1638819994.png\n",
        "\n",
        "**Hint:** For more details about the Vision API, please visit https://platform.openai.com/docs/guides/vision"
      ],
      "metadata": {
        "id": "tncwPsifEnNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-5: Write a code that includes prompts and Vision API calls. [2.5 Points]\n",
        "\n",
        "### EXPECTED-OUTPUT (may vary):\n",
        "# <TODO_5_OUTPUT_BEGIN>\n",
        "# The image features two large centipedes, each with visible legs.\n",
        "# Each centipede has 21 pairs of legs, making a total of 42 legs per centipede.\n",
        "# Since there are two centipedes, the total number of centipede legs in the image is 42 + 42 = 84 legs.\n",
        "# <TODO_5_OUTPUT_END>\n",
        "\n",
        "print(\"<TODO_5_OUTPUT_BEGIN>\")\n",
        "\n",
        "# <Write your code here>\n",
        "\n",
        "print(\"<TODO_5_OUTPUT_END>\")"
      ],
      "metadata": {
        "id": "c8paIq0iEfwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Building ReAct Agent with Langchain [15 Points]\n",
        "\n",
        "In this task, you are required to implement code that defines tools for the LLM to use. The tools include:\n",
        "* Loan limit calculator (TODO-6)\n",
        "* KBTG's job search (TODO-7)\n"
      ],
      "metadata": {
        "id": "i86w1NSC_WYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-6: Write loan limit calculator function with the following logic [5 Points]\n",
        "\n",
        "* income <= 0 , loan_limit = 0\n",
        "* 0 < income < 15000 , loan_limit = 1 x income\n",
        "* 15000 <= income < 50000, loan_limit = 3 x income\n",
        "* 50000 <= income, loan_limit = 5 x income"
      ],
      "metadata": {
        "id": "Sh6AHYD7HuYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-6: Write loan limit calculator function with the following logic [5 Points]\n",
        "### income <= 0 , loan_limit = 0\n",
        "### 0 < income < 15000 , loan_limit = 1 x income\n",
        "### 15000 <= income < 50000, loan_limit = 3 x income\n",
        "### 50000 <= income, loan_limit = 5 x income\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def calculate_loan_limit(monthly_income: int):\n",
        "    \"\"\"calculate loan limit from monthly income\"\"\"\n",
        "    # <Write your code here>\n",
        "    return 0\n",
        "\n",
        "### EXPECTED-OUTPUT:\n",
        "# <TODO_6_OUTPUT_BEGIN>\n",
        "# INPUT: -999\n",
        "# OUTPUT: 0\n",
        "# INPUT: 0\n",
        "# OUTPUT: 0\n",
        "# INPUT: 14500\n",
        "# OUTPUT: 14500\n",
        "# INPUT: 15000\n",
        "# OUTPUT: 45000\n",
        "# INPUT: 50000\n",
        "# OUTPUT: 250000\n",
        "# INPUT: 100000\n",
        "# OUTPUT: 500000\n",
        "# <TODO_6_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "print(\"<TODO_6_OUTPUT_BEGIN>\")\n",
        "income_lists = [-999, 0, 14500, 15000, 50000, 100000]\n",
        "for income in income_lists:\n",
        "    print(\"INPUT:\", income)\n",
        "    print(\"OUTPUT:\", int(calculate_loan_limit({\"monthly_income\": income})))\n",
        "print(\"<TODO_6_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "ubXvxYFz_WoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-7: Extract the remaining fields. (job_title, job_location) [5 Points]\n",
        "\n",
        "In this task, the majority of the code is provided. This code makes a POST request to www.kbtg.tech to retrieve job openings based on the given keywords. Your task is to extract the remaining job information, including the job title and job location.\n",
        "\n",
        "\n",
        "**Hint:** An example for extracting job_company_name is provided. You might need to **log the raw response** from the API to complete the code."
      ],
      "metadata": {
        "id": "jDXtbDbpH44P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import requests\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def search_kbtg_jobs(keyword: str):\n",
        "    \"\"\"searching the opening job.\"\"\"\n",
        "\n",
        "    query = re.sub(r'\\s+', '+', keyword)\n",
        "    res = requests.post(\n",
        "        \"https://www.kbtg.tech/career-factor\",\n",
        "        headers={'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8'},\n",
        "        data=f\"page=1&limit=3&keyword={query}\"\n",
        "    )\n",
        "    res = res.content.decode(\"utf-8\")\n",
        "    res = json.loads(res)[\"data\"]\n",
        "\n",
        "    job_search_results = []\n",
        "    for job_data in res:\n",
        "\n",
        "        ### TODO-7: Extract the remaining fields. (job_title, job_location) [5 Points]\n",
        "        job_company_name = job_data[\"jobRequisition\"][\"legalEntity_obj\"][\"name\"]\n",
        "        job_title = # <Write your code here>\n",
        "        job_location = # <Write your code here>\n",
        "\n",
        "        job_search_results.append({\"title\": job_title, \"company\": job_company_name, \"location\": job_location})\n",
        "    return job_search_results\n",
        "\n",
        "### EXPECTED-OUTPUT (may vary):\n",
        "# <TODO_7_OUTPUT_BEGIN>\n",
        "# [{'title': 'Business Analyst (Wealth)',\n",
        "#   'company': 'KASIKORN SOFT',\n",
        "#   'location': 'KBTG Building'},\n",
        "#  {'title': 'Advanced Business Analyst (Digital Channel)',\n",
        "#   'company': 'KASIKORN SOFT',\n",
        "#   'location': 'KBTG Building'},\n",
        "#  {'title': 'Business Analyst (Non-Mobile)',\n",
        "#   'company': 'KASIKORN SOFT',\n",
        "#   'location': 'KBTG Building'}]\n",
        "# <TODO_7_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "print(\"<TODO_7_OUTPUT_BEGIN>\")\n",
        "print(search_kbtg_jobs(\"Analyst\"))\n",
        "print(\"<TODO_7_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "xyl6b23jExN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "model = ChatOpenAI(openai_api_key=userdata.get(\"OPENAI_API_KEY\"),\n",
        "                   model=\"gpt-4o-mini\", temperature=0.0)\n",
        "\n",
        "agent_executor = create_react_agent(model, [search_kbtg_jobs, calculate_loan_limit])\n",
        "\n",
        "def log_lc_response(response):\n",
        "    for msg in response['messages']:\n",
        "        msg = msg.to_json()\n",
        "        if msg[\"id\"][-1] == \"HumanMessage\":\n",
        "            print(\"HUMAN:\", msg[\"kwargs\"][\"content\"])\n",
        "        elif msg[\"id\"][-1] == \"AIMessage\":\n",
        "            if \"additional_kwargs\" in msg[\"kwargs\"]:\n",
        "                print(\"TOOL-REQ::\", msg[\"kwargs\"][\"additional_kwargs\"][\"tool_calls\"][0][\"function\"])\n",
        "            else:\n",
        "                print(\"AI:\", msg[\"kwargs\"][\"content\"])\n",
        "        elif msg[\"id\"][-1] == \"ToolMessage\":\n",
        "            print(\"TOOL-RES:\", msg[\"kwargs\"][\"content\"])"
      ],
      "metadata": {
        "id": "J-P4ga2jEzGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-8: Test agent with tools (calculate_loan_limit) [2 Points]\n",
        "\n",
        "The code is already provided. Run this cell to validate that TODO-6 and TODO-7 are correct."
      ],
      "metadata": {
        "id": "1OV62wwuH_BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-8: Test agent with tools (calculate_loan_limit) [2 Points]\n",
        "\n",
        "### EXPECTED-OUTPUT:\n",
        "# <TODO_8_OUTPUT_BEGIN>\n",
        "# HUMAN: If I have a monthly income of 30,000, what loan amount can I get?\n",
        "# TOOL-REQ:: {'arguments': '{\"monthly_income\":30000}', 'name': 'calculate_loan_limit'}\n",
        "# TOOL-RES: 90000\n",
        "# AI: With a monthly income of 30,000, you can get a loan amount of up to 90,000.\n",
        "# <TODO_8_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content= \"If I have a monthly income of 30,000, what loan amount can I get?\")]}\n",
        ")\n",
        "#\n",
        "print(\"<TODO_8_OUTPUT_BEGIN>\")\n",
        "log_lc_response(response)\n",
        "print(\"<TODO_8_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "S76wBjuVE2oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-9: Test agent with tools (search_kbtg_jobs) [2 Points]\n",
        "\n",
        "The code is already provided. Run this cell to validate that TODO-6 and TODO-7 are correct."
      ],
      "metadata": {
        "id": "VYzsp8dsID0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-9: Test agent with tools (search_kbtg_jobs) [2 Points]\n",
        "\n",
        "### EXPECTED-OUTPUT:\n",
        "# <TODO_9_OUTPUT_BEGIN>\n",
        "# HUMAN: Hello, Do you have Analyst Job opening?\n",
        "# TOOL-REQ:: {'arguments': '{\"keyword\":\"Analyst\"}', 'name': 'search_kbtg_jobs'}\n",
        "# TOOL-RES: [{\"title\": \"Business Analyst (Wealth)\", \"company\": \"KASIKORN SOFT\", \"location\": \"KBTG Building\"}, {\"title\": \"Advanced Business Analyst (Digital Channel)\", \"company\": \"KASIKORN SOFT\", \"location\": \"KBTG Building\"}, {\"title\": \"Business Analyst (Non-Mobile)\", \"company\": \"KASIKORN SOFT\", \"location\": \"KBTG Building\"}]\n",
        "# AI: Yes, there are several Analyst job openings available:\n",
        "#\n",
        "# 1. **Business Analyst (Wealth)**\n",
        "#    - Company: KASIKORN SOFT\n",
        "#    - Location: KBTG Building\n",
        "#\n",
        "# 2. **Advanced Business Analyst (Digital Channel)**\n",
        "#    - Company: KASIKORN SOFT\n",
        "#    - Location: KBTG Building\n",
        "#\n",
        "# 3. **Business Analyst (Non-Mobile)**\n",
        "#    - Company: KASIKORN SOFT\n",
        "#    - Location: KBTG Building\n",
        "#\n",
        "# If you need more information about any specific position, feel free to ask!\n",
        "# <TODO_9_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content= \"Hello, Do you have Analyst job opening?\")]}\n",
        ")\n",
        "#\n",
        "print(\"<TODO_9_OUTPUT_BEGIN>\")\n",
        "log_lc_response(response)\n",
        "print(\"<TODO_9_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "ax1COP_PE3Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TODO-10: Test agent without tools in general cases. [1 Point]\n",
        "\n",
        "The code is already provided. Run this cell to validate that TODO-6 and TODO-7 are correct."
      ],
      "metadata": {
        "id": "QbPY2P0OII5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TODO-10: Test agent without tools in general cases. [1 Point]\n",
        "\n",
        "### EXPECTED-OUTPUT:\n",
        "# <TODO_10_OUTPUT_BEGIN>\n",
        "# HUMAN: Howdy?\n",
        "# AI: Hello! How can I assist you today?\n",
        "# <TODO_10_OUTPUT_END>\n",
        "\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################\n",
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content= \"Howdy?\")]}\n",
        ")\n",
        "#\n",
        "print(\"<TODO_10_OUTPUT_BEGIN>\")\n",
        "log_lc_response(response)\n",
        "print(\"<TODO_10_OUTPUT_END>\")\n",
        "################ DON'T CHANGE THE CODE IN THIS BLOCK ################"
      ],
      "metadata": {
        "id": "f0moO-eHE41v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: LLM Applications [35 Points]"
      ],
      "metadata": {
        "id": "OXCcq7YP_pt2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: LLM Application Laboratory"
      ],
      "metadata": {
        "id": "_aJrARtZ_TuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Laboratory Overview </h1>\n",
        "\n",
        "<h2> Scenario </h2>\n",
        "\n",
        "You manage a platform that hosts fine food reviews from various sources. To improve search functionality and enhance user experience, you need to categorize these reviews, analyze sentiment, and identify key topics such as taste, packaging, and freshness.\n",
        "\n",
        "All data is stored in a CSV file and should be loaded into a Pandas `DataFrame` for processing.\n",
        "\n",
        "<h2> Objective </h2>\n",
        "\n",
        "The objective of this lab is to provide learners with hands-on experience in categorizing and analyzing food reviews using LangChain and OpenAI embeddings. Learners will:\n",
        "\n",
        "- Define and implement a structured tagging schema for fine food reviews.\n",
        "- Automatically categorize reviews and identify key topics using LangChain.\n",
        "- Perform semantic search using text embeddings and cosine similarity.\n",
        "\n",
        "By the end of this lab, learners will be able to build systems that enhance the discoverability and organization of food reviews through automated tagging and advanced search techniques.\n",
        "\n",
        "\n",
        "<h2> Tasks </h2>\n",
        "\n",
        "1. **Set up Environment**:\n",
        "\n",
        "    - Install and import all necessary libraries for LangChain Tagging and Semantic Search\n",
        "    - Load and pre-process data\n",
        "\n",
        "2. **Create a `chain` object for tagging food reviews**:\n",
        "\n",
        "    The `chain` should be composed of a `prompt_template` for the Tagging-LLM and an `llm` using the `gpt-3.5-turbo` model (or any other **OpenAI GPT** model) with a structured output format based on the defined `schema`.\n",
        "   \n",
        "    The required tagging fields in the `schema` are as follows:\n",
        "\n",
        "    - `food_category`: A **string** representing the food category (e.g., Candy, Chips, Tea).\n",
        "    - `sentiment`: A **string** indicating the sentiment of the review (Positive, Negative, Neutral).\n",
        "    - `topic_of_concern`: A **list of strings** identifying the main aspects discussed in the review (e.g., Taste, Freshness, Packaging).\n",
        "\n",
        "3. **Apply tagging function to review data**:\n",
        "\n",
        "    Add all tagging field as the new columns.\n",
        "\n",
        "4. **Define Utility Functions**:\n",
        "   - One function should be designed to vectorize/embed text data.\n",
        "   - The second function should compare the cosine similarity between text embeddings.\n",
        "\n",
        "5. **Apply your functions to answer the provided questions**:\n",
        "   - Perform text embedding to the `tag` columns\n",
        "   - Analyze and apply semantic search to answer the given question\n",
        "\n",
        "<h2> Grading </h2>\n",
        "\n",
        "This task will be evaluated based on two key outputs:\n",
        "\n",
        "1. The `schema` implemented for the LLM tagging task.\n",
        "2. Your responses to Questions 5.1 through 5.3.\n",
        "\n",
        "The final evaluation will be based on **the output generated in the last cell** of this task, so please ensure you run it before submitting."
      ],
      "metadata": {
        "id": "BWbOtN11_cj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Set up Environment"
      ],
      "metadata": {
        "id": "QZulIxQl-pHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Install and import all necessary libraries for LangChain Tagging and Semantic Search"
      ],
      "metadata": {
        "id": "-uMbhHxl-sTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain and LLM-related Module"
      ],
      "metadata": {
        "id": "KVJMZFfya1GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "sj2Vvx0r9EgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Manipulation Module"
      ],
      "metadata": {
        "id": "kwLDSxvra7bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "PtDHaqSALKAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Load and pre-process data"
      ],
      "metadata": {
        "id": "0nJ8RBGVKOK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Data Explanation\n",
        "\n",
        "The dataset used in this lab is sourced from the [Amazon Fine Food Reviews](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews) dataset on Kaggle. This dataset contains over 500,000 reviews of fine foods from Amazon, including details such as product information, review text, rating, and helpfulness scores.\n",
        "\n",
        "In this lab, we will randomly select 100 rows for Tagging and Semantic Search task. And only a subset of the original columns will be used.\n",
        "\n",
        "**Data in this Lab:**\n",
        "- **`review_id`**: Unique identifier for each review.\n",
        "- **`product_id`**: Unique identifier for the product.\n",
        "- **`user_id`**: Unique identifier for the user.\n",
        "- **`review_score`**: The rating given by the user (from 1 to 5).\n",
        "- **`review_dt`**: The datetime for the review.\n",
        "- **`review_title`**: A title of the review.\n",
        "- **`review_text`**: The main content of the review.\n",
        "\n",
        "**Usage:**\n",
        "The focus columns that will be used for tagging task are `review_title` and `review_text`. The goal is to automatically tag reviews with meaningful labels and enable semantic search for better insights and recommendations.\n",
        "\n",
        "**Source:**\n",
        "You can find more details about the dataset [here](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews).\n"
      ],
      "metadata": {
        "id": "gzUN8ar7Z52s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Data Acquisition\n",
        "\n",
        "Run the `Downloading Cell` and `Preprocessing Cell` to load and pre-process the data. If succeed, the dataset will be stored in variable `df`. **DO NOT CHANGE THE CODE!!!**\n",
        "\n",
        "*Note:* If the `Downloading Cell` malfunction (cannot accquired dataset), please follow these instructions:\n",
        "1. Go download the dataset directly from [here](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews).\n",
        "2. Unzip the file and upload the file named `Reviews.csv` into Colab's File Explorer.\n",
        "3. Try rerun the `Preprocessing Cell` and check variable `df`"
      ],
      "metadata": {
        "id": "vts_nIUEgcA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading Cell\n",
        "\n",
        "!kaggle datasets download -d snap/amazon-fine-food-reviews\n",
        "!unzip amazon-fine-food-reviews.zip\n",
        "!rm -r amazon-fine-food-reviews.zip database.sqlite hashes.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2ocifQ7I3xU",
        "outputId": "5257af58-3972-45f1-810a-982edd1ea436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-fine-food-reviews.zip to /content\n",
            " 96% 233M/242M [00:01<00:00, 163MB/s]\n",
            "100% 242M/242M [00:01<00:00, 185MB/s]\n",
            "Archive:  amazon-fine-food-reviews.zip\n",
            "  inflating: Reviews.csv             \n",
            "  inflating: database.sqlite         \n",
            "  inflating: hashes.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Cell\n",
        "\n",
        "# Read CSV\n",
        "df = pd.read_csv('Reviews.csv')\n",
        "\n",
        "# Rename columns\n",
        "df = df.rename(columns={\n",
        "    'Text': 'review_text',\n",
        "    'Summary': 'review_title',\n",
        "    'Id': 'review_id',\n",
        "    'ProductId': 'product_id',\n",
        "    'UserId': 'user_id',\n",
        "    'Score': 'review_score'\n",
        "})\n",
        "\n",
        "# Convert second to Datetime\n",
        "df['review_dt'] = pd.to_datetime(df['Time'], unit='s')\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df = df.drop(['ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time'], axis=1)\n",
        "\n",
        "# Sample for 100 rows\n",
        "# random_state should be 42. DO NOT CHANGE THE SEED!!!. This will affect your final grading.\n",
        "df = df.sample(100, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bXxd4oCIY3T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "YPQpMcbeKfmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a `chain` object for tagging food reviews"
      ],
      "metadata": {
        "id": "xcMaOFR4bX_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Set up API Key and GPT Model"
      ],
      "metadata": {
        "id": "T5t4nf1VJzQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "GPT_MODEL = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "j3TeCIewJyeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Construct `prompt_template` and `llm` object"
      ],
      "metadata": {
        "id": "tLfBATyOMsrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 Complete the Code for a Review Tagging Prompt Template\n",
        "\n",
        "**Task:**\n",
        "Define a `template` for an LLM in a review tagging task.\n",
        "The output should follow the structure defined in the schema.\n",
        "The `template` will receive two arguments, `title` and `text`, from column `review_title` and `review_text`, which will be passed to the LLM for tagging.\n",
        "\n",
        "**Instructions:**\n",
        "- Replace `<Fill in your prompt here>` with the text that adheres to the schema requirements.\n",
        "- Ensure the placeholders `{title}` and `{text}` are correctly referenced in the prompt."
      ],
      "metadata": {
        "id": "JxISrAepUuQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "\n",
        "    <Fill in your prompt here>\n",
        "\n",
        "    **Title**: {title}\n",
        "    **Review**: {review}\n",
        "\"\"\"\n",
        "\n",
        "tagging_prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "HMOEv6NwMPCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.2 Define an LLM Object with Specific Parameters\n",
        "\n",
        "**Task:**\n",
        "Use the `ChatOpenAI` class to initilize an `llm` object.\n",
        "This should be created by passing only the following three arguments:\n",
        "- `openai_api_key`: `OPENAI_API_KEY`\n",
        "- `model`: `GPT_MODEL`\n",
        "- `temperature`: Set to `0` for deterministic output\n",
        "\n",
        "**Instructions:**\n",
        "Replace the placeholder below with the correct initialization using the ChatOpenAI class."
      ],
      "metadata": {
        "id": "fFoHTsT1VOqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = _  # Your code here"
      ],
      "metadata": {
        "id": "gjjKmpA5KCmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.3 Complete the `FoodTaggingSchema` Class Definition **[20 points]**\n",
        "\n",
        "**Task:**  \n",
        "Define a dictionary-based schema for tagging food reviews using the `FoodTaggingSchema` class. Your job is to complete the class by filling in the type hints and descriptions according to the criteria below:\n",
        "\n",
        "- `food_category`: A **string** representing the food category (e.g., Candy, Chips, Tea, Coffee). The category should **not be too specific** (e.g., brand names) and **not too general** (e.g., \"drinks\", \"meal\", \"food\").\n",
        "- `sentiment`: A **string** indicating the sentiment of the review (Positive, Negative, Neutral).\n",
        "- `topic_of_concern`: A **list of strings** identifying the key aspects discussed in the review (e.g., Taste, Freshness, Packaging). The list should contain a maximum of 3 items.\n",
        "\n",
        "*Note:* For the `food_category` field, there may be cases where the product being reviewed is **not food** or is **unidentifiable**. Ensure your prompt accounts for these scenarios:\n",
        "- Use **`NONE_FOOD`** when the product reviewed is not food.\n",
        "- Use **`UNIDENTIFY`** when the category cannot be determined.\n",
        "\n",
        "**Instructions:**\n",
        "\n",
        "- Complete the pydantic-class by defining the fields with correct type hints and descriptions.\n",
        "- Ensure the descriptions are detailed and meaningful for each field.\n"
      ],
      "metadata": {
        "id": "K-6otvD6Vjdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foodTaggingSchema = {\n",
        "    \"title\": \"FoodTaggingSchema\",\n",
        "    \"type\": \"object\",\n",
        "    \"description\": \"Schema for tagging food reviews based on food category, sentiment, and topics of concern.\",\n",
        "    \"properties\": {\n",
        "        \"food_category\": {\n",
        "            \"type\": \"_\", # fill in the blank\n",
        "            \"description\": \"\"\"\n",
        "\n",
        "            <Fill in your description here>\n",
        "\n",
        "            \"\"\"\n",
        "        },\n",
        "        \"sentiment\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"\"\"\n",
        "\n",
        "            <Fill in your description here>\n",
        "\n",
        "            \"\"\",\n",
        "            \"enum\": [_, _, \"neutral\"], # fill in 2 more choices for sentiment analysis\n",
        "            \"default\": \"neutral\"\n",
        "        },\n",
        "        \"topic_of_concern\": {\n",
        "            \"type\": \"array\",\n",
        "            \"description\": \"\"\"\n",
        "\n",
        "            <Fill in your description here>\n",
        "\n",
        "            \"\"\",\n",
        "            \"items\": {\n",
        "                \"type\": \"_\" # fill in type of element in the array\n",
        "            },\n",
        "            \"maxItems\": _ # fill in the blank\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\"food_category\", \"sentiment\", \"topic_of_concern\"]\n",
        "}"
      ],
      "metadata": {
        "id": "RpZzWS54t67p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.4 Complete the code to define a structured output LLM\n",
        "\n"
      ],
      "metadata": {
        "id": "MymkF9uyXFPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_structured = llm._(foodTaggingSchema) # fill in the blank"
      ],
      "metadata": {
        "id": "3P866LaKXZ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.5 Define `chain` object for Review Tagging"
      ],
      "metadata": {
        "id": "YTcuh4QNX-cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = tagging_prompt | llm_structured"
      ],
      "metadata": {
        "id": "ENh-N5_5YJ-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Implement a Function to Tag a Review\n",
        "\n",
        "**Task:**\n",
        "Define a function named `tag_review` that:\n",
        "- Accepts two parameters: `title` and `review`.\n",
        "- Prepares an input dictionary containing these two arguments.\n",
        "- Invokes a predefined chain using the `input` dictionary.\n",
        "- Extracts and returns the following information from the response:\n",
        "  - `food_category`: The category of food being reviewed.\n",
        "  - `sentiment`: The sentiment of the review (e.g., Positive, Negative, Neutral).\n",
        "  - `topic_of_concern`: A list of topics that the review is concerned with.\n",
        "\n",
        "**Instructions:**\n",
        "1. Replace `chain._(input)` with the correct function or method call that processes the input.\n",
        "2. Ensure the return statement accurately extracts the `food_category`, `sentiment`, and `topic_of_concern` fields from the response **respectively**.\n"
      ],
      "metadata": {
        "id": "GO-lR3VGcjqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_review(title, review):\n",
        "    input = {\n",
        "        \"title\": title,\n",
        "        \"review\": review\n",
        "    }\n",
        "\n",
        "    # Feed the input using `invoke` method\n",
        "    res = chain._(input) # fill in the blank\n",
        "\n",
        "    # Extract and return the required fields from the response\n",
        "    return res['_'], _['sentiment'], res['topic_of_concern'] # fill in the blank"
      ],
      "metadata": {
        "id": "VWpgGWYIcsil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Apply the `tag_review` Function to a DataFrame\n",
        "\n",
        "Apply the tag_review function to tag reviews in a DataFrame `df` by extracting and labeling the following fields:\n",
        "\n",
        "- food_category\n",
        "- sentiment\n",
        "- topic_of_concern\n",
        "\n",
        "This process may take some time and will use your OpenAI API credits.\n"
      ],
      "metadata": {
        "id": "S5mVHlY0iL5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['food_category', 'sentiment', 'topic_of_concern']] = (\n",
        "    df\n",
        "    .progress_apply(\n",
        "        lambda x: tag_review(x['review_title'], x['review_text']),\n",
        "        axis=1,\n",
        "        result_type='expand'\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "B2PgpjF4fHYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "981920b9-e495-41f5-e853-100ad4586687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:28<00:00,  1.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Define Utility Functions\n",
        "\n",
        "In this section, we will create utility functions to support semantic search. A `client` object and `get_embedding` function is already provided, which takes input text and applies GPT’s embedding to generate vector representations. Your task is to implement two additional functions that will be essential for performing semantic search."
      ],
      "metadata": {
        "id": "F9JXreF7k5bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate API connections\n",
        "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Define Embedding function\n",
        "def get_embedding(text):\n",
        "    response = client.embeddings.create(\n",
        "        input=text,\n",
        "        model='text-embedding-3-large'\n",
        "    )\n",
        "    return response.data[0].embedding"
      ],
      "metadata": {
        "id": "IsAeYRu1NwmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Implement a Function to Calculate Cosine Similarity\n",
        "\n",
        "Task:\n",
        "Complete the `cosine_similarity` function to calculate the cosine similarity between two vectors `vec1` and `vec2`.\n",
        "The cosine similarity is defined as the dot product of the vectors divided by the product of their magnitudes.\n",
        "\n",
        "Formula:\n",
        "Cosine Similarity = (vec1 · vec2) / (||vec1|| * ||vec2||)\n",
        "\n",
        "Instructions:\n",
        "1. Replace the placeholders (`_`) with the correct NumPy function calls.\n",
        "2. Ensure that the dot product and norms are calculated correctly."
      ],
      "metadata": {
        "id": "_XoIFhtNNg_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = np._(_, vec2) / (np.linalg.norm(_) * _._._(vec2)) # fill in the blank\n",
        "    return dot_product"
      ],
      "metadata": {
        "id": "lwB1bZeINaEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Implement a Function for Semantic Search\n",
        "\n",
        "Task:\n",
        "Complete the `semantic_search` function, which performs a semantic search based on cosine similarity.\n",
        "The function should:\n",
        "- Convert the query into an embedding.\n",
        "- Compute the similarity between the query embedding and the embeddings in the specified DataFrame column.\n",
        "- Sort the DataFrame based on the similarity scores.\n",
        "\n",
        "Instructions:\n",
        "1. Fill in the blanks (`_`) with the appropriate function calls to convert the query and column values into embeddings and calculate cosine similarity.\n",
        "2. Ensure the DataFrame is sorted correctly based on the similarity scores.\n",
        "\n",
        "Parameter Explanation:\n",
        "- `query`: A string representing the search query. This will be converted into an embedding.\n",
        "- `df`: A Pandas DataFrame containing the data to be searched.\n",
        "- `col`: The name of the column in `df` that contains the text or embeddings to be compared with the query."
      ],
      "metadata": {
        "id": "D5T3otDfPIvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search(query, df, col):\n",
        "    query_emb = _(query) # fill in the blank\n",
        "    df['similarity'] = df[col].apply(lambda x: _(_, x)) # fill in the blank\n",
        "    return df._('similarity', ascending=False)"
      ],
      "metadata": {
        "id": "a-cpyaZAN0-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Apply your functions to answer the provided questions\n",
        "   \n",
        "Use the created functions and the tagged data to perform semantic searches and derive insights based on the questions given."
      ],
      "metadata": {
        "id": "zKxB6RoZk7a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 How many positive/negative/nuetral reviews from this data? **[5 points]**\n",
        "\n",
        "*Hint:* `value_counts` method"
      ],
      "metadata": {
        "id": "8ZPahk7ClFYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count values of `sentiment` column\n",
        "df[_]._() # fill in the blank"
      ],
      "metadata": {
        "id": "_gO9DWSRrZHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Answer to 5.1 (please run the cell after filling-in the answer) {\"run\":\"auto\",\"vertical-output\":true,\"display-mode\":\"form\"}\n",
        "positive_reviews = 0 # @param {\"type\":\"integer\"}\n",
        "negative_reviews = 0 # @param {\"type\":\"integer\"}\n",
        "neutral_reviews = 0 # @param {\"type\":\"integer\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "JccTzXM5plfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 List me 3 `review_id` mentioned about 'Healthy Product' or any related terms. **[5 points]**"
      ],
      "metadata": {
        "id": "WKrrJZ6glLC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.1 Concatenate `topic_of_concern` column into single string\n",
        "\n",
        "- Use `, ` as delimiter\n",
        "- Save the concatenated string into new column, `toc_concat`\n",
        "\n",
        "*Hint:* Use `join` method"
      ],
      "metadata": {
        "id": "5emLdiYtiaNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['toc_concat'] = df['_'].progress_apply(lambda x: ', '._(x)) # fill in the blank"
      ],
      "metadata": {
        "id": "s5XIRCjiiZSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.2 Apply Embedding to the concatenated column\n",
        "\n",
        "- Apply embedding to column `toc_concat`\n",
        "- Save the embedded value into new column, `toc_emb`"
      ],
      "metadata": {
        "id": "QpL7PbwUjBE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['_'] = df['toc_concat'].progress_apply(lambda x: _(x)) # fill in the blank"
      ],
      "metadata": {
        "id": "m9Q4ri80pAB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.3 Apply Similarity of the embedded column with the key word `Healthy Product`\n",
        "\n",
        "- Define `Healthy Product` as `query` for searching\n",
        "- Use semantic search function to get similarity score between `query` and `toc_emb`"
      ],
      "metadata": {
        "id": "jAt65AnHkBgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'Healthy Product'\n",
        "df_result_hp = semantic_search(df=df, query=query, col='toc_emb')"
      ],
      "metadata": {
        "id": "yZrwIba6kvR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.4 Analyze the search result from similarity score\n",
        "\n",
        "- Look into rows with best score, check their original `topic_of_concern` column if it's related to **Healthy Product**\n",
        "- If so, paste their `review_id` into the following form to answer the question"
      ],
      "metadata": {
        "id": "L-3PjBi9HV56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_hp.sort_values('similarity', ascending=False).head(3)"
      ],
      "metadata": {
        "id": "nIQf8HSjkztr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Answer to 5.2 (please run the cell after filling-in the answer){\"run\":\"auto\",\"vertical-output\":true,\"display-mode\":\"form\"}\n",
        "first_id = \"\" # @param {\"type\":\"string\"}\n",
        "second_id = \"\" # @param {\"type\":\"string\"}\n",
        "third_id = \"\" # @param {\"type\":\"string\"}\n"
      ],
      "metadata": {
        "id": "eXNZ0jWywR-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 What is the most common drink that is in the top 10 similarity score with the word `Beverages`? **[5 points]**"
      ],
      "metadata": {
        "id": "TJP5P_JzlQm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.1 Apply Embedding to the `food_category`\n",
        "\n",
        "- Save the embedded value into new column, `food_cat_emb`"
      ],
      "metadata": {
        "id": "PXtJl2A1Q0xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['food_cat_emb'] = df['_']._(lambda x: get_embedding(x)) # fill in the blank"
      ],
      "metadata": {
        "id": "9fmUR2wSPm1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5cf75a12-ddd2-4175-8222-b1a2f4689758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:34<00:00,  2.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.2 Apply Similarity of the embedded column with the key word `Beverages`\n",
        "\n",
        "- Define `Beverages` as `query` for searching\n",
        "- Use semantic search function to get similarity score between `query` and column `food_cat_emb`"
      ],
      "metadata": {
        "id": "wf6IEFX5RRvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = '_' # fill in the blank\n",
        "df_result_bev = semantic_search(query=query, df=df, col='_') # fill in the blank"
      ],
      "metadata": {
        "id": "2ANTAoa0pqHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.3 Analyze the top 10 search result from similarity score\n",
        "\n",
        "- Look at the top 10 rows with best `cosine_similarity` score, check their for their food category"
      ],
      "metadata": {
        "id": "iA9Da3XHRcZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result_bev.sort_values('similarity', ascending=_).head(10) # fill in the blank"
      ],
      "metadata": {
        "id": "8rSZYUIpPjQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Answer to 5.3 (please run the cell after filling-in the answer){\"run\":\"auto\",\"vertical-output\":true}\n",
        "most_common_beverage = \"\" # @param {\"type\":\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "COLQxGrQlQNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer for grading\n",
        "\n",
        "Run all the following cells to print the answer out. This will contribute to a total of **35 points**. **Make sure to submit the notebook with all the answers printed out.**\n",
        "\n",
        "If `NameError` raises, try running the `Answer Form` of the question."
      ],
      "metadata": {
        "id": "1S3RcGo105Fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Tagging Schema Answer [20 points]"
      ],
      "metadata": {
        "id": "wBYt1eyHvIV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<TODO_SCHEMA_FILL_OUTPUT_BEGIN>\")\n",
        "print(foodTaggingSchema['properties']['food_category']['type'])\n",
        "print(\"<ANS_SPLIT>\")\n",
        "print('|'.join(foodTaggingSchema['properties']['sentiment']['enum']))\n",
        "print(\"<ANS_SPLIT>\")\n",
        "print(foodTaggingSchema['properties']['topic_of_concern']['items']['type'])\n",
        "print(\"<ANS_SPLIT>\")\n",
        "print(foodTaggingSchema['properties']['topic_of_concern']['maxItems'])\n",
        "print(\"<TODO_SCHEMA_FILL_OUTPUT_END>\")\n",
        "print(\"<TODO_SCHEMA_OUTPUT_BEGIN>\")\n",
        "print(foodTaggingSchema)\n",
        "print(\"<TODO_SCHEMA_OUTPUT_END>\")"
      ],
      "metadata": {
        "id": "FOAm7rPjvB6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Answer [5 points]"
      ],
      "metadata": {
        "id": "xh8ELOFt05F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<TODO_5_1_OUTPUT_BEGIN>\")\n",
        "print(positive_reviews)\n",
        "print(\"<ANS_SPLIT>\")\n",
        "print(negative_reviews)\n",
        "print(\"<ANS_SPLIT>\")\n",
        "print(neutral_reviews)\n",
        "print(\"TODO_5_1_OUTPUT_END\")"
      ],
      "metadata": {
        "id": "uwaun-83waBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Answer [5 points]"
      ],
      "metadata": {
        "id": "R8hRAcJY05F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<TODO_5_2_OUTPUT_BEGIN>\")\n",
        "print(first_id)\n",
        "print(\"<ANS_SPLIT>\")\n",
        "print(second_id)\n",
        "print(\"<ANS_SPLIT>\")\n",
        "print(third_id)\n",
        "print(\"<TODO_5_2_OUTPUT_BEGIN>\")"
      ],
      "metadata": {
        "id": "t4CxBwmh05F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Answer [5 points]"
      ],
      "metadata": {
        "id": "VGjui5Pp05F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"<TODO_5_3_OUTPUT_BEGIN>\")\n",
        "print(most_common_beverage)\n",
        "print(\"<TODO_5_3_OUTPUT_BEGIN>\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "p17H3K-105F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Sentiment Analysis [30 Points]\n",
        "\n",
        "#### Sentiment analysis is the process of determining the emotional tone behind a body of text, typically classifying it as positive, negative, or neutral. It often involves preprocessing and cleaning the text data to remove noise, followed by vectorizing the text to transform it into a numerical format suitable for analysis. These steps are crucial for building accurate models that can effectively analyze sentiment in large datasets.\n",
        "\n",
        "#### In this task, you need to complete four sub-task functions related to the Sentiment Analysis process covered in class. You can use a sanity check to verify the correctness of your functions before submitting.\n",
        "\n",
        "#### **Make sure that you run all sanity check cells before submitting**"
      ],
      "metadata": {
        "id": "tb3d0HFlABtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "import re\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "EdEiUjaIBOJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "QFJQQUPRBPoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Initialize SpaCy and NLTK\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYd9vJ7DBUGV",
        "outputId": "4fbc7e43-0c10-422c-b9d1-c28092f4aaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Clean & Preprocess text with REGEX [7.5 Points]\n",
        "\n",
        "#### Cleaning and preprocessing text with regex in Python involves using regular expressions to identify and remove unwanted elements from the text, such as special characters, numbers, or extra spaces. This process is essential for preparing raw text data for analysis by normalizing the text, reducing noise, and ensuring consistency. By applying regex patterns, you can efficiently clean the text, making it more suitable for tasks like tokenization, vectorization, and sentiment analysis."
      ],
      "metadata": {
        "id": "OW0FNnDkA_rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TO DO: Use regex to remove number (0-9) and these 3 symbols (, . !) from the text_input\n",
        "### Hint: re.sub() can be used for replacing occurrences of a regex pattern with a specified replacement string. Also, You can use sanity check for debugging.\n",
        "### Expected Output: Text without number (0-9) and these 3 symbols (, . !)\n",
        "\n",
        "def regex_clean(text_input):\n",
        "  ### BEGIN YOUR ANSWER\n",
        "  raise NotImplementedError\n",
        "  ### END YOUR ANSWER"
      ],
      "metadata": {
        "id": "pdQgCQT2AAdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ***** PLEASE RUN AND DO NOT CHANGE ANYTHING IN THIS CELL ******\n",
        "### Sanity Check: regex_clean\n",
        "\n",
        "regex_clean_1 = \"Hello, world0123!\"\n",
        "regex_clean_2 = \"1.I won lottery.!!!\"\n",
        "\n",
        "assert regex_clean(regex_clean_1) == \"Hello world\", \"regex_clean_1: Wrong Output\"\n",
        "print(\"regex_clean_1: Passed!\")\n",
        "\n",
        "assert regex_clean(regex_clean_2) == \"I won lottery\", \"regex_clean_2: Wrong Output\"\n",
        "print(\"regex_clean_2: Passed!\")"
      ],
      "metadata": {
        "id": "BKNMlMd1Bo0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Vectorize text using SpaCy [7.5 Points]\n",
        "\n",
        "#### Vectorizing text using SpaCy involves converting text data into numerical representations, called vectors, that capture the meaning and context of the words or phrases. SpaCy provides powerful tools like pre-trained word embeddings that transform text into dense vectors, which reflect semantic similarities and differences. These vectors can then be used for various natural language processing tasks, such as sentiment analysis, text classification, or clustering, enabling machine learning models to understand and process text data more effectively."
      ],
      "metadata": {
        "id": "44ybKp8kBj6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TO DO: Use SpaCy \"en_core_web_lg\" to vectorize the text_input and save value as vector_output\n",
        "### Hint: You can call the variable 'nlp' in the function.\n",
        "### Expected Output: Vector of the text_input\n",
        "\n",
        "def spacy_vectorize(text_input):\n",
        "  ### BEGIN YOUR ANSWER\n",
        "  raise NotImplementedError\n",
        "  ### END YOUR ANSWER"
      ],
      "metadata": {
        "id": "y6MUxlGz_3xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ***** PLEASE RUN AND DO NOT CHANGE ANYTHING IN THIS CELL ******\n",
        "### Sanity Check: spacy_vectorize\n",
        "\n",
        "spacy_vectorize_1 = \"Hello World\"\n",
        "spacy_vectorize_2 = \"This is a cat.\"\n",
        "\n",
        "assert np.allclose(spacy_vectorize(spacy_vectorize_1), [ 1.9091499 , -0.45174998,  6.0755    , -2.40725   ,  1.6430551 ,\n",
        "        1.22375   , -0.16766998, -2.6821    ,  2.07438   ,  3.67405   ,\n",
        "        1.06575   ,  1.355615  , -2.1858    ,  3.25365   , -0.96880007,\n",
        "       -0.84369993,  3.050255  ,  1.929425  ,  0.266375  , -1.4181999 ,\n",
        "        2.23065   ,  0.13395   ,  0.342965  , -1.3394501 ,  0.47084004,\n",
        "        4.08997   , -4.8279247 ,  0.82527   , -0.23190004, -0.78024995,\n",
        "       -0.64109   ,  1.39115   ,  1.01615   ,  2.80055   , -3.33231   ,\n",
        "        2.213785  , -0.04525006, -0.45984995, -2.32922   , -2.417888  ,\n",
        "        0.20391501,  1.33049   , -0.563985  ,  1.6517899 , -2.4878802 ,\n",
        "       -3.03185   , -4.56585   ,  1.74856   , -1.357615  , -3.959625  ,\n",
        "       -0.69825   , -2.26605   , -0.72382504, -2.1701    ,  1.7167001 ,\n",
        "        1.4455001 , -0.5869755 , -0.85075   , -2.0085502 ,  0.3819    ,\n",
        "        1.27522   ,  2.0743499 , -0.825005  ,  3.4989    ,  2.49142   ,\n",
        "       -0.873825  , -2.3759599 ,  0.15710002,  4.71345   , -0.96141493,\n",
        "        0.97319996,  2.310585  , -0.8499249 , -1.6558999 , -1.2397499 ,\n",
        "       -3.4123    , -0.290385  ,  1.2902601 ,  4.49415   , -0.531245  ,\n",
        "       -0.30260015, -0.5022    , -1.4202    ,  2.66235   ,  2.96855   ,\n",
        "       -2.3820899 , -0.51495004, -3.87338   , -2.63205   , -4.5396    ,\n",
        "       -0.962265  ,  3.0814    , -1.27605   , -1.2235    , -4.5558    ,\n",
        "        1.517935  , -0.57454   , -1.419395  , -1.28969   ,  1.01775   ,\n",
        "        1.5958949 , -0.93831   ,  0.29061398,  1.4059498 , -0.40600002,\n",
        "        0.8541    , -0.68939996, -0.8835    ,  0.232621  ,  0.258035  ,\n",
        "        2.1965249 ,  1.03335   , -1.72347   ,  0.54244006,  0.31351   ,\n",
        "       -2.8723998 ,  0.831015  , -1.2166994 , -0.57189   ,  2.9512    ,\n",
        "       -1.379975  ,  0.05383   ,  3.03583   ,  0.05925   ,  3.7099    ,\n",
        "        1.7822    ,  0.90089995, -0.93752   , -0.21735   , -0.35956   ,\n",
        "        0.37635005,  3.199625  , -0.17940009, -1.82325   , -0.800265  ,\n",
        "       -2.078645  ,  1.5732349 , -0.98045003, -2.45435   ,  3.3913498 ,\n",
        "        0.816275  ,  1.681535  ,  1.073505  ,  1.8717201 , -2.70605   ,\n",
        "       -0.81369   , -4.704305  , -0.44801   , -1.9599199 ,  0.331795  ,\n",
        "        1.54905   ,  0.448628  , -3.3199    ,  0.476015  , -1.8448    ,\n",
        "       -0.20492001,  2.029295  ,  0.07160002,  2.6872551 , -1.6288    ,\n",
        "        1.235345  ,  1.317705  , -1.9263599 , -0.38435   , -3.817655  ,\n",
        "       -1.144415  , -2.076225  , -1.4848001 ,  1.5587001 , -3.9872901 ,\n",
        "       -1.8787    , -0.4929    , -3.1566    ,  2.332205  , -0.27949995,\n",
        "       -0.89615506, -0.972535  ,  0.66885   , -0.097805  , -1.4099    ,\n",
        "        0.54473996,  2.80335   , -2.785755  , -1.03169   ,  0.14777   ,\n",
        "        4.7942    , -0.43314993, -1.8141501 ,  2.64845   ,  1.3605    ,\n",
        "       -1.07244   ,  3.8125    ,  0.4349    ,  3.1717026 ,  1.961475  ,\n",
        "       -0.32695   , -1.58219   ,  2.23975   ,  1.095645  ,  3.9083    ,\n",
        "        1.88625   , -0.103234  , -0.88906   , -0.5008501 ,  5.5821753 ,\n",
        "       -0.35721502, -0.81245005,  1.1631999 , -2.726985  , -0.3377    ,\n",
        "        1.5778999 ,  2.3084202 , -0.77995   , -1.0862    , -0.85148996,\n",
        "        1.3574849 , -1.22574   ,  0.48182   ,  2.32545   , -3.6890001 ,\n",
        "       -0.553385  ,  0.51283497, -2.75875   , -1.10565   , -6.53037   ,\n",
        "       -0.86206496,  0.32465   ,  2.204345  , -2.70668   ,  1.98566   ,\n",
        "       -1.339125  ,  1.17286   , -0.297028  ,  1.8505    , -0.36110997,\n",
        "        1.0040851 , -1.047425  ,  0.82317   ,  0.478855  ,  0.33419997,\n",
        "        2.25532   ,  0.473225  ,  1.1447845 , -0.43174   , -0.54912496,\n",
        "       -0.94259   , -1.265725  , -1.479     , -1.01386   ,  0.2139035 ,\n",
        "       -1.92481   , -4.812345  , -1.598245  , -1.266505  , -0.6402    ,\n",
        "       -3.97715   ,  0.97725004, -4.9416847 ,  1.13679   ,  2.8118    ,\n",
        "        0.829285  , -4.5960503 ,  1.8581    , -0.70976   , -1.4105451 ,\n",
        "       -3.03318   , -2.25385   , -0.45599997, -1.1853501 ,  1.188738  ,\n",
        "        0.31739998,  0.855105  ,  1.8125999 ,  1.8716501 , -1.5424001 ,\n",
        "       -0.26905   , -1.5464    ,  0.50355005,  0.10933   ,  2.1044002 ,\n",
        "        0.82834995,  0.517655  ,  2.0570998 , -3.6235    , -0.42475003,\n",
        "        0.8547085 ,  3.8453999 , -0.36260003,  0.8638995 ,  3.07476   ,\n",
        "        1.7916199 , -0.07744998,  0.73646003,  1.40165   , -1.0778465 ,\n",
        "       -3.5363998 ,  0.75514895, -1.166235  , -3.014495  , -1.0041499 ]) == True, \"spacy_vectorize_1: Wrong Output\"\n",
        "print(\"spacy_vectorize_1: Passed!\")\n",
        "\n",
        "assert np.allclose(spacy_vectorize(spacy_vectorize_2), [-5.1525068e-01,  3.3550200e+00, -3.1942058e+00, -3.7386200e+00,\n",
        "        6.2822609e+00, -5.1502001e-01,  3.1933394e-01,  2.0876498e+00,\n",
        "        1.4574479e+00,  1.1849389e-01,  1.0310520e+01, -2.3752013e-01,\n",
        "       -1.0822041e+00,  8.7533605e-01,  2.1434102e+00,  2.7598598e+00,\n",
        "        1.7363818e+00,  2.4873600e+00,  9.3288791e-01, -8.0104399e-01,\n",
        "        7.9022008e-01,  1.4068760e+00, -3.2576861e+00, -1.4497462e-01,\n",
        "       -3.5770001e+00, -2.9040198e+00, -2.8258998e+00, -2.1282201e+00,\n",
        "       -3.2122798e+00,  4.4936083e-02, -9.3070203e-01, -4.8406202e-01,\n",
        "       -3.2052238e+00, -8.0821002e-01, -4.3008800e+00,  9.2272198e-01,\n",
        "        8.8425463e-01,  4.6460000e-01,  5.6586399e+00, -5.5996007e-01,\n",
        "       -1.9406722e+00,  4.9976605e-01,  1.9287260e+00, -4.2426005e-01,\n",
        "       -2.4993002e+00,  2.3217678e+00,  3.4900203e+00, -3.3036518e+00,\n",
        "       -2.2066395e+00, -5.9411001e-01, -6.2006605e-01,  1.6725420e+00,\n",
        "        3.4256377e+00, -3.1799202e+00,  5.1342005e-01, -3.2105997e-01,\n",
        "        2.9841797e+00,  8.2749999e-01, -9.0579844e-01,  6.0143000e-01,\n",
        "        1.4841321e+00, -1.7128880e+00, -3.8300015e-02, -5.5789995e-01,\n",
        "       -2.7657757e+00, -8.8112041e-02, -3.4344602e+00, -6.1846356e+00,\n",
        "        2.9752400e+00,  2.4428980e+00, -4.2204332e-02,  3.0471997e+00,\n",
        "       -4.6080999e+00, -2.0597601e-01, -4.3766794e-01,  1.3226600e+00,\n",
        "       -2.7763600e+00,  2.7712102e+00, -2.7255280e+00, -7.9127997e-01,\n",
        "       -5.3278599e+00, -2.5735700e+00,  6.4166194e-01, -1.3083364e+00,\n",
        "        2.3878360e+00, -1.5716702e+00,  2.2275715e+00,  5.7804799e-01,\n",
        "        3.7506242e+00, -2.9679279e+00, -8.5738802e-01, -4.6682458e+00,\n",
        "        3.9121425e+00, -7.4809999e+00,  6.8826199e-01, -4.5307999e+00,\n",
        "       -4.4429404e-01,  8.1760027e-02, -4.2538404e-01, -4.9222360e+00,\n",
        "        7.6188183e-01,  7.7960002e-01,  6.2873201e+00,  6.4020529e+00,\n",
        "        2.1447120e+00,  4.6194186e+00,  7.8504041e-02,  2.3271642e+00,\n",
        "       -3.5233657e+00,  2.9579301e+00, -2.3646080e+00,  4.1450725e+00,\n",
        "       -5.2480614e-01,  4.8736520e+00,  5.7585800e-01, -1.2049781e+00,\n",
        "       -2.6510799e+00,  2.4680258e-03,  2.7278199e+00, -6.6711998e-01,\n",
        "       -1.2842820e+00, -2.0238199e+00, -1.5410120e+00,  5.8798203e+00,\n",
        "       -1.9881001e+00, -6.8943801e+00,  3.4059811e-02, -6.2057996e-01,\n",
        "        2.7027278e+00, -2.8297079e+00, -2.8847060e+00, -1.2029999e+00,\n",
        "        5.8111439e+00, -7.5403605e+00, -4.8309737e-01,  8.7368393e-01,\n",
        "        2.2249398e+00, -4.3276601e+00,  5.3056002e+00, -2.8657200e+00,\n",
        "       -1.8121380e+00, -2.4238411e-01,  3.0637522e+00,  2.2479560e+00,\n",
        "        1.4982580e+00,  1.1447401e+00, -3.6077163e+00, -3.3542195e-01,\n",
        "       -3.4776998e-01,  3.6801600e+00,  2.5131402e+00,  5.4348302e+00,\n",
        "        1.0040540e+00,  2.4681199e+00,  2.4649601e-01,  2.4969239e+00,\n",
        "        5.1022220e+00,  3.4736018e+00,  2.8122789e-01,  3.5790208e-01,\n",
        "       -1.9040579e+00, -2.0078850e+00,  1.5827520e+00,  2.6213200e+00,\n",
        "       -4.8154202e+00, -3.1938400e+00, -3.7035301e+00,  5.6587391e+00,\n",
        "        2.6762402e+00, -6.9629952e-02,  3.8428657e+00, -8.7008762e-01,\n",
        "        3.2447200e+00,  1.1510401e+00,  1.2628801e-01, -3.8476224e+00,\n",
        "        6.0685790e-01, -2.0399571e-03, -3.7674537e+00, -7.1674001e-01,\n",
        "       -1.0998760e+00,  1.5341840e+00,  1.6909180e+00, -3.6566799e+00,\n",
        "       -3.3844619e+00, -7.9374206e-01, -3.7961879e+00, -3.4601181e+00,\n",
        "       -9.8252803e-01,  3.4114003e+00, -2.1496696e+00, -7.1959990e-01,\n",
        "       -2.2053800e+00, -3.7677798e+00,  2.7276399e+00, -1.6924605e-01,\n",
        "       -3.0168099e+00, -3.6999942e-03,  1.2836021e+00, -3.8780200e+00,\n",
        "        5.0803035e-01, -9.0892601e-01, -3.5374198e+00, -3.6654201e+00,\n",
        "        1.5899861e+00,  1.8346682e+00, -6.6831002e+00,  1.5564820e+00,\n",
        "       -3.7149956e+00, -3.7630200e+00,  4.5250001e+00,  2.0020201e+00,\n",
        "       -4.0279999e-01,  2.5854721e+00,  1.1243280e+00,  1.7673798e-01,\n",
        "       -8.1888998e-01, -2.1178601e+00, -2.4210601e+00,  4.5965600e-01,\n",
        "       -2.7663758e+00, -2.4932561e+00,  1.5002759e+00, -3.0449599e-01,\n",
        "       -3.7684008e-01, -7.2592008e-01,  2.7756200e+00, -2.7147999e-01,\n",
        "        4.4642601e+00, -1.6031481e+00, -3.9000988e-03, -9.0072603e+00,\n",
        "        1.7786318e+00,  4.6200242e+00, -4.9403801e+00,  3.1929597e-01,\n",
        "       -1.3880199e+00,  9.0721129e-03,  1.3808960e+00,  1.5602281e+00,\n",
        "        1.7240620e+00,  6.1998796e-01,  3.5996997e+00,  2.3757000e+00,\n",
        "       -4.1756921e+00, -2.2395339e+00, -3.8822072e+00,  2.0884180e+00,\n",
        "       -1.7062393e-01,  3.8123124e+00,  2.4698810e-01,  4.3285400e-01,\n",
        "       -5.1090002e+00, -4.3618999e+00, -2.2364192e+00, -1.0938101e+00,\n",
        "        3.9004002e+00,  5.5234003e+00,  7.7447397e-01, -2.3161778e+00,\n",
        "       -1.2803020e+00,  2.8454998e+00,  2.4919000e+00,  6.7252998e+00,\n",
        "       -1.9188640e+00, -1.0170660e+00, -2.4665399e+00,  7.8406394e-01,\n",
        "       -3.7017677e+00,  1.0613760e+00,  5.0155802e+00, -1.6745160e+00,\n",
        "       -5.1563793e-01, -2.8973603e+00,  2.0842299e+00,  8.4648001e-01,\n",
        "        2.1587601e+00,  2.6430061e+00, -5.7316399e-01,  1.3787849e+00,\n",
        "        1.5152200e-01, -3.9843597e+00, -4.6193199e+00,  1.4414209e+00,\n",
        "        8.4691324e+00, -1.7156000e+00,  2.9018404e+00,  1.5891964e-02,\n",
        "       -2.0408401e+00,  3.0835021e+00,  1.3132802e+00,  9.1946000e-01,\n",
        "        5.1444678e+00,  5.1536405e-01, -1.0884761e+00,  3.9948399e+00,\n",
        "       -7.9524004e-01,  1.5913141e+00, -3.6228924e+00,  2.8538461e+00]) == True, \"spacy_vectorize_2: Wrong Output\"\n",
        "print(\"spacy_vectorize_2: Passed!\")"
      ],
      "metadata": {
        "id": "ixpwCjnVB8xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Find text similarity using SpaCy [7.5 Points]\n",
        "\n",
        "#### SpaCy provides a built-in function to calculate cosine similarity, which measures how similar two texts are by comparing the angles between their vector representations. This method, with values ranging from -1 to 1, is effective for assessing semantic similarity in tasks like document comparison and clustering."
      ],
      "metadata": {
        "id": "9LSPcLGwBkgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TO DO: Use SpaCy \"en_core_web_lg\" to find cosine similarity of 2 texts\n",
        "### Hint: You can call the variable 'nlp' in the function.\n",
        "### Expected Output: Vector of the text_input\n",
        "\n",
        "def spacy_similarity(text_input_1, text_input_2):\n",
        "  ### BEGIN YOUR ANSWER\n",
        "  raise NotImplementedError\n",
        "  ### END YOUR ANSWER"
      ],
      "metadata": {
        "id": "BGSXV4BU_huf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ***** PLEASE RUN AND DO NOT CHANGE ANYTHING IN THIS CELL ******\n",
        "### Sanity Check: spacy_similarity\n",
        "\n",
        "spacy_similarity_1_a = \"Hello World\"\n",
        "spacy_similarity_1_b = \"This is a cat.\"\n",
        "spacy_similarity_2_a = \"Water\"\n",
        "spacy_similarity_2_b = \"Drinking\"\n",
        "\n",
        "assert math.isclose(spacy_similarity(spacy_similarity_1_a, spacy_similarity_1_b), 0.011677389356738732) == True, \"spacy_similarity_1: Wrong Output\"\n",
        "print(\"spacy_similarity_1: Passed!\")\n",
        "\n",
        "assert math.isclose(spacy_similarity(spacy_similarity_2_a, spacy_similarity_2_b), 0.4627892310102833) == True, \"spacy_similarity_2: Wrong Output\"\n",
        "print(\"spacy_similarity_2: Passed!\")"
      ],
      "metadata": {
        "id": "hr2n-uHqCFfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Analyze text sentiment using NLTK \"VADER\" [7.5 Points]\n",
        "\n",
        "#### VADER (Valence Aware Dictionary and sEntiment Reasoner) in NLTK is a tool for analyzing text sentiment, specifically designed to capture both the polarity (positive, negative, neutral) and intensity of sentiments expressed in social media and other informal text. VADER uses a pre-built lexicon of words and assigns them sentiment scores, allowing it to effectively handle slang, emojis, and negations. It's easy to implement and provides quick, reliable sentiment analysis, making it ideal for applications like social media monitoring and opinion mining."
      ],
      "metadata": {
        "id": "qj0fLTK_B0ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TO DO: Use NLTK \"VADER\" to analyze sentiment in text data\n",
        "### Hint: You can call the variable 'sid' in the function.\n",
        "### Expected Output: NLTK VADER sentiment output format like -> {'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4927}\n",
        "\n",
        "def nltk_sentimentanalysis(text_input):\n",
        "  ### BEGIN YOUR ANSWER\n",
        "  raise NotImplementedError\n",
        "  ### END YOUR ANSWER"
      ],
      "metadata": {
        "id": "YAG0mxtIB0_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ***** PLEASE RUN AND DO NOT CHANGE ANYTHING IN THIS CELL ******\n",
        "### Sanity Check: nltk_sentimentanalysis\n",
        "\n",
        "nltk_sentimentanalysis_1 = \"It is marvelous.\"\n",
        "nltk_sentimentanalysis_2 = \"This movie is suck.\"\n",
        "\n",
        "assert nltk_sentimentanalysis(nltk_sentimentanalysis_1) == {'neg': 0.0, 'neu': 0.339, 'pos': 0.661, 'compound': 0.5994}, \"nltk_sentimentanalysis_1: Wrong Output\"\n",
        "print(\"nltk_sentimentanalysis_1: Passed!\")\n",
        "\n",
        "assert nltk_sentimentanalysis(nltk_sentimentanalysis_2) == {'neg': 0.492, 'neu': 0.508, 'pos': 0.0, 'compound': -0.4404}, \"nltk_sentimentanalysis_2: Wrong Output\"\n",
        "print(\"nltk_sentimentanalysis_2: Passed!\")"
      ],
      "metadata": {
        "id": "dxKiB0BHCJbb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}